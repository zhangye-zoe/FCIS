{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert the .tif image to .png image for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "# --- Function to convert a single TIF file ---\n",
    "def convert_tif_to_png(input_filepath: str, output_filepath: str) -> bool:\n",
    "    \"\"\"\n",
    "    Convert a .tif file to .png format and save it.\n",
    "\n",
    "    Args:\n",
    "        input_filepath: Path to the input .tif file.\n",
    "        output_filepath: Path to save the output .png file.\n",
    "\n",
    "    Returns:\n",
    "        True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the .tif file\n",
    "        with Image.open(input_filepath) as img:\n",
    "            # Convert image to RGB if it's not (PNG typically expects RGB or RGBA)\n",
    "            # This can help avoid issues with specific TIFF formats (e.g., paletted)\n",
    "            if img.mode != 'RGB' and img.mode != 'RGBA':\n",
    "                 img = img.convert('RGB')\n",
    "\n",
    "            # Save as .png\n",
    "            # The optimize=True and quality=95 are optional but can help with file size\n",
    "            img.save(output_filepath, format=\"PNG\", optimize=True, quality=95)\n",
    "            # print(f\"Successfully converted {os.path.basename(input_filepath)}\") # Optional: print success per file\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {input_filepath}\", file=sys.stderr)\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred processing {os.path.basename(input_filepath)}: {e}\", file=sys.stderr)\n",
    "        return False\n",
    "\n",
    "# --- Function to process all TIF files in a directory ---\n",
    "def process_image_directory(input_dir: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Process all .tif files in an input directory, convert them to .png,\n",
    "    and save them in an output directory.\n",
    "\n",
    "    Args:\n",
    "        input_dir: Path to the directory containing input .tif files.\n",
    "        output_dir: Path to the directory where output .png files will be saved.\n",
    "    \"\"\"\n",
    "    print(f\"Processing images from: {input_dir}\")\n",
    "    print(f\"Saving converted images to: {output_dir}\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # List all entries in the input directory\n",
    "    entries = os.listdir(input_dir)\n",
    "    print(f\"Found {len(entries)} entries in {input_dir}\")\n",
    "\n",
    "    converted_count = 0\n",
    "    failed_count = 0\n",
    "\n",
    "    # Iterate through each entry\n",
    "    for entry_name in entries:\n",
    "        input_filepath = os.path.join(input_dir, entry_name)\n",
    "\n",
    "        # Check if it's a file and ends with .tif (case-insensitive)\n",
    "        if os.path.isfile(input_filepath) and entry_name.lower().endswith('.tif'):\n",
    "            try:\n",
    "                # Get the base filename without extension\n",
    "                base_name = os.path.splitext(entry_name)[0]\n",
    "                output_filename = f\"{base_name}.png\"\n",
    "                output_filepath = os.path.join(output_dir, output_filename)\n",
    "\n",
    "                # Perform the conversion\n",
    "                print(f\"Converting {entry_name}...\") # Print before conversion\n",
    "                if convert_tif_to_png(input_filepath, output_filepath):\n",
    "                    converted_count += 1\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                # Catch potential errors during path manipulation or naming\n",
    "                print(f\"An unexpected error occurred processing entry {entry_name}: {e}\", file=sys.stderr)\n",
    "                failed_count += 1\n",
    "        # else:\n",
    "            # Optional: print messages for ignored entries (e.g., directories, non-tif files)\n",
    "            # print(f\"Skipping {entry_name} (not a .tif file)\")\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Processing complete for {input_dir}\")\n",
    "    print(f\"Successfully converted: {converted_count}\")\n",
    "    print(f\"Failed to convert: {failed_count}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# --- Main Execution Block (suitable for a notebook cell) ---\n",
    "\n",
    "# Define the base paths for input and output\n",
    "base_download_path = \"./data/DSB2018/original\" # Corrected 'orignal' to 'original'\n",
    "base_save_path = \"./data/DSB2018/visual\"\n",
    "\n",
    "# Define the splits to process (train and test)\n",
    "splits = ['train', 'test', 'val']\n",
    "\n",
    "# Process each split\n",
    "for split in splits:\n",
    "    input_dir = os.path.join(base_download_path, split, 'images')\n",
    "    output_dir = os.path.join(base_save_path, split, 'images')\n",
    "\n",
    "    # Check if the input directory exists before processing\n",
    "    if os.path.isdir(input_dir):\n",
    "        process_image_directory(input_dir, output_dir)\n",
    "    else:\n",
    "        print(f\"\\n--- Skipping {split} split ---\")\n",
    "        print(f\"Input directory not found: {input_dir}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "print(\"\\nAll specified splits processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert .tif mask to .npy and .png format for visualization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image # Used for opening the TIFF file\n",
    "import random\n",
    "import cv2 # Used for saving the colorized PNG\n",
    "import sys # Used for printing errors to stderr\n",
    "\n",
    "# --- Function to colorize a segmentation map ---\n",
    "def colorize_seg_map(seg_map: np.ndarray, palette: dict = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Colorizes a segmentation map using random RGB colors for unique IDs.\n",
    "\n",
    "    Args:\n",
    "        seg_map: A 2D NumPy array representing the segmentation map, where each\n",
    "                 unique integer value corresponds to a segment ID.\n",
    "        palette: An optional dictionary mapping segment IDs to RGB color tuples\n",
    "                 (e.g., {1: (255, 0, 0), 2: (0, 255, 0)}). If None, a random\n",
    "                 palette is generated for the unique IDs present in the map.\n",
    "\n",
    "    Returns:\n",
    "        A 3D NumPy array (height, width, 3) representing the colorized segmentation map\n",
    "        in RGB format (uint8). Background (ID 0) is left black.\n",
    "    \"\"\"\n",
    "    # Ensure the segmentation map is a NumPy array\n",
    "    if not isinstance(seg_map, np.ndarray):\n",
    "        seg_map = np.array(seg_map)\n",
    "\n",
    "    # Create an empty RGB image of the same shape as the segmentation map\n",
    "    colorful_seg_map = np.zeros((*seg_map.shape, 3), dtype=np.uint8)\n",
    "\n",
    "    # Get the unique segment IDs present in the map\n",
    "    unique_ids = np.unique(seg_map)\n",
    "\n",
    "    # Generate a palette if none is provided\n",
    "    if palette is None:\n",
    "        palette = {}\n",
    "        # Generate a random color for each unique ID (excluding background 0)\n",
    "        for seg_id in unique_ids:\n",
    "            if seg_id == 0:\n",
    "                continue # Skip background\n",
    "            # Generate random integer colors between 0 and 255\n",
    "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            palette[seg_id] = color\n",
    "    else:\n",
    "        # Validate provided palette contains colors for unique IDs (optional but good practice)\n",
    "        # For simplicity, we'll assume the provided palette is valid for now.\n",
    "        pass # Add validation logic here if needed\n",
    "\n",
    "    # Apply colors to the segmentation map\n",
    "    for seg_id, color in palette.items():\n",
    "        # Ensure we only color IDs present in the map and not the background (ID 0)\n",
    "        if seg_id != 0 and seg_id in unique_ids:\n",
    "             # Use boolean indexing to assign the color to all pixels with this segment ID\n",
    "            colorful_seg_map[seg_map == seg_id, :] = color\n",
    "\n",
    "    return colorful_seg_map\n",
    "\n",
    "# --- Function to process a single TIFF segmentation file ---\n",
    "def process_segmentation_file(input_filepath: str, output_base_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Converts a TIFF segmentation mask to a NumPy array (.npy) and\n",
    "    a colorized PNG image (.png).\n",
    "\n",
    "    Args:\n",
    "        input_filepath: Path to the input .tif segmentation file.\n",
    "        output_base_path: Base path for saving the output files (without extension).\n",
    "                          The .npy and .png extensions will be added automatically.\n",
    "\n",
    "    Returns:\n",
    "        True if processing was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the .tif file using Pillow\n",
    "        with Image.open(input_filepath) as img:\n",
    "            # Convert image to a NumPy array\n",
    "            # Ensure dtype is appropriate for segmentation IDs (e.g., uint16 or int32 if IDs are large)\n",
    "            # For typical masks, uint8 might suffice, but uint16 is safer.\n",
    "            img_array = np.array(img, dtype=np.uint16) # Use uint16 for potentially larger IDs\n",
    "\n",
    "            # Generate colorized mask\n",
    "            color_mask = colorize_seg_map(img_array)\n",
    "\n",
    "            # Define output file paths\n",
    "            output_npy_path = f\"{output_base_path}.npy\"\n",
    "            output_png_path = f\"{output_base_path}.png\"\n",
    "\n",
    "            # Save the NumPy array as a .npy file\n",
    "            np.save(output_npy_path, img_array)\n",
    "            # Save the colorized mask as a .png file using OpenCV\n",
    "            # OpenCV saves in BGR format, so we need to convert RGB to BGR\n",
    "            cv2.imwrite(output_png_path, cv2.cvtColor(color_mask, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # print(f\"Processed {os.path.basename(input_filepath)}\") # Optional: print success per file\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {input_filepath}\", file=sys.stderr)\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred processing {os.path.basename(input_filepath)}: {e}\", file=sys.stderr)\n",
    "        return False\n",
    "\n",
    "# --- Function to process all segmentation files in a directory ---\n",
    "def process_segmentation_directory(input_dir: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Processes all .tif segmentation mask files in an input directory,\n",
    "    converting each to a .npy array and a colorized .png image,\n",
    "    and saves them in the output directory.\n",
    "\n",
    "    Args:\n",
    "        input_dir: Path to the directory containing input .tif files.\n",
    "        output_dir: Path to the directory where output .npy and .png files will be saved.\n",
    "    \"\"\"\n",
    "    print(f\"Processing segmentation masks from: {input_dir}\")\n",
    "    print(f\"Saving processed files to: {output_dir}\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # List all entries in the input directory\n",
    "    entries = os.listdir(input_dir)\n",
    "    print(f\"Found {len(entries)} entries in {input_dir}\")\n",
    "\n",
    "    processed_count = 0\n",
    "    failed_count = 0\n",
    "\n",
    "    # Iterate through each entry\n",
    "    for entry_name in entries:\n",
    "        input_filepath = os.path.join(input_dir, entry_name)\n",
    "\n",
    "        # Check if it's a file and ends with .tif (case-insensitive)\n",
    "        if os.path.isfile(input_filepath) and entry_name.lower().endswith('.tif'):\n",
    "            try:\n",
    "                # Get the base filename without extension\n",
    "                base_name = os.path.splitext(entry_name)[0]\n",
    "                # Define the base path for the output files (without extension)\n",
    "                output_base_path = os.path.join(output_dir, base_name)\n",
    "\n",
    "                # Process the file\n",
    "                print(f\"Processing {entry_name}...\") # Print before processing\n",
    "                if process_segmentation_file(input_filepath, output_base_path):\n",
    "                    processed_count += 1\n",
    "                else:\n",
    "                    failed_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                # Catch potential errors during path manipulation or naming\n",
    "                print(f\"An unexpected error occurred processing entry {entry_name}: {e}\", file=sys.stderr)\n",
    "                failed_count += 1\n",
    "        # else:\n",
    "            # Optional: print messages for ignored entries (e.g., directories, non-tif files)\n",
    "            # print(f\"Skipping {entry_name} (not a .tif file or not a file)\")\n",
    "\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Processing complete for {input_dir}\")\n",
    "    print(f\"Successfully processed: {processed_count}\")\n",
    "    print(f\"Failed to process: {failed_count}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- Main Execution Block (suitable for a notebook cell) ---\n",
    "\n",
    "# Define the base paths for input and output\n",
    "# Assuming the structure is like ./data/DSB2018/original/test/masks/*.tif\n",
    "base_input_path = \"./data/DSB2018/original\"\n",
    "base_output_path = \"./data/DSB2018/visual\" # This seems to be where you want the output\n",
    "\n",
    "# Define the splits to process (e.g., 'test', 'train')\n",
    "# Based on your original code, it seems you were processing the 'test' split.\n",
    "# You can add 'train' if needed.\n",
    "splits = ['train', 'test', 'val'] # Add 'train' here if you want to process train masks too\n",
    "\n",
    "# Process each split\n",
    "for split in splits:\n",
    "    # Construct the full input directory path for the masks\n",
    "    # Assuming masks are in a 'masks' subdirectory within the split\n",
    "    input_masks_dir = os.path.join(base_input_path, split, 'masks') # Assuming a 'masks' subdir\n",
    "    # Construct the full output directory path\n",
    "    output_processed_dir = os.path.join(base_output_path, split, 'masks') # Saving processed masks here\n",
    "\n",
    "    # Check if the input directory exists before processing\n",
    "    if os.path.isdir(input_masks_dir):\n",
    "        process_segmentation_directory(input_masks_dir, output_processed_dir)\n",
    "    else:\n",
    "        print(f\"\\n--- Skipping {split} split ---\")\n",
    "        print(f\"Input masks directory not found: {input_masks_dir}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nAll specified splits processed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Splitting images and masks to 256*256 (HoverNet training format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sys # Used for printing errors to stderr\n",
    "\n",
    "# --- Function to split and save patches for a single image and mask pair ---\n",
    "def split_and_save_patches(\n",
    "    input_image_path: str,\n",
    "    input_mask_path: str,\n",
    "    output_split_dir: str, # Directory to save all patches for this split\n",
    "    image_base_name: str, # Base name of the original image (e.g., '1')\n",
    "    patch_size: int = 256,\n",
    "    step: int = 256\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Split an image and its corresponding mask into patches and save each\n",
    "    combined patch (image + mask channel) as a separate .npy file\n",
    "    in the specified output directory for the split.\n",
    "\n",
    "    Args:\n",
    "        input_image_path: Path to the input .png image file.\n",
    "        input_mask_path: Path to the input .npy mask file.\n",
    "        output_split_dir: The single directory where all patches for this split\n",
    "                          will be saved. This directory is assumed to exist\n",
    "                          (created by the calling function).\n",
    "        image_base_name: The base filename of the original image (without extension),\n",
    "                         used for naming the output patches.\n",
    "        patch_size: The height and width of each square patch (in pixels).\n",
    "        step: The step size (in pixels) for the sliding window. Use step < patch_size\n",
    "              for overlapping patches, and step = patch_size for non-overlapping patches.\n",
    "\n",
    "    Returns:\n",
    "        The number of patches successfully saved for this image/mask pair,\n",
    "        or -1 if an error occurred.\n",
    "    \"\"\"\n",
    "    print(f\"Processing image: {os.path.basename(input_image_path)}\")\n",
    "    print(f\"Using mask: {os.path.basename(input_mask_path)}\")\n",
    "    print(f\"Saving patches to: {output_split_dir}\")\n",
    "\n",
    "    try:\n",
    "        # Load the image and mask\n",
    "        # Use convert(\"RGB\") to ensure 3 channels, even if input is grayscale PNG\n",
    "        image = np.array(Image.open(input_image_path).convert(\"RGB\"))\n",
    "        mask = np.load(input_mask_path)\n",
    "\n",
    "        # Get dimensions of image and mask\n",
    "        img_h, img_w, img_c = image.shape\n",
    "        mask_h, mask_w = mask.shape\n",
    "\n",
    "        # Ensure the dimensions of image and mask match\n",
    "        if (img_h, img_w) != (mask_h, mask_w):\n",
    "            raise ValueError(\n",
    "                f\"Dimensions mismatch: Image is {img_h}x{img_w}, Mask is {mask_h}x{mask_w}\"\n",
    "            )\n",
    "\n",
    "        # Basic check for patch size validity\n",
    "        if patch_size <= 0 or step <= 0:\n",
    "             raise ValueError(\"Patch size and step must be positive integers.\")\n",
    "        if patch_size > img_h or patch_size > img_w:\n",
    "             print(f\"Warning: Patch size ({patch_size}) is larger than image dimensions ({img_h}x{img_w}). No patches will be generated for {image_base_name}.\", file=sys.stderr)\n",
    "             return 0 # No patches can be generated\n",
    "\n",
    "        # Split the image and mask into patches using a sliding window\n",
    "        image_patch_count = 0 # Counter for patches from this specific image\n",
    "        # Calculate the range for the sliding window, ensuring the patch fits entirely\n",
    "        for i in range(0, img_h - patch_size + 1, step):\n",
    "            for j in range(0, img_w - patch_size + 1, step):\n",
    "                # Extract the image patch (all channels)\n",
    "                img_patch = image[i : i + patch_size, j : j + patch_size, :]\n",
    "                # Extract the mask patch\n",
    "                mask_patch = mask[i : i + patch_size, j : j + patch_size]\n",
    "\n",
    "                # Combine the image patch (3 channels) and mask patch (1 channel)\n",
    "                # Use np.expand_dims or [..., np.newaxis] to add a channel dimension to the mask\n",
    "                combined_patch = np.concatenate(\n",
    "                    (img_patch, np.expand_dims(mask_patch, axis=-1)), axis=-1\n",
    "                )\n",
    "\n",
    "                # Save the combined patch as a .npy file\n",
    "                # Name the patch file using original image base name and sequential patch count\n",
    "                patch_filename = os.path.join(\n",
    "                    output_split_dir, f\"{image_base_name}_{image_patch_count}.npy\"\n",
    "                )\n",
    "                np.save(patch_filename, combined_patch)\n",
    "                image_patch_count += 1\n",
    "\n",
    "        print(f\"Successfully saved {image_patch_count} patches for {os.path.basename(input_image_path)}\")\n",
    "        return image_patch_count\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Input file not found: {e}\", file=sys.stderr)\n",
    "        return -1\n",
    "    except ValueError as e:\n",
    "        print(f\"Data error for {os.path.basename(input_image_path)}: {e}\", file=sys.stderr)\n",
    "        return -1\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred processing {os.path.basename(input_image_path)}: {e}\", file=sys.stderr)\n",
    "        return -1\n",
    "\n",
    "# --- Function to process all images and masks in specified directories ---\n",
    "def process_split_for_patching(\n",
    "    split_name: str,\n",
    "    base_input_image_dir: str,\n",
    "    base_input_mask_dir: str,\n",
    "    base_output_patch_dir: str, # Base directory where output split folders will be created\n",
    "    patch_size: int = 256,\n",
    "    step: int = 256\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes all image/mask pairs within a specific data split (e.g., 'test')\n",
    "    and saves all their patches into a single output directory for that split.\n",
    "\n",
    "    Args:\n",
    "        split_name: The name of the data split (e.g., 'test').\n",
    "        base_input_image_dir: Base directory containing image subdirectories for splits.\n",
    "                              Expected structure: base_input_image_dir / split_name / ...\n",
    "        base_input_mask_dir: Base directory containing mask subdirectories for splits.\n",
    "                             Expected structure: base_input_mask_dir / split_name / ...\n",
    "        base_output_patch_dir: Base directory where the single output directory for this\n",
    "                                split's patches will be created.\n",
    "                                Expected structure: base_output_patch_dir / split_name / ...\n",
    "        patch_size: Size of the patch.\n",
    "        step: Step size for sliding window.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Processing split: {split_name} ---\")\n",
    "\n",
    "    # Construct the full input directories for images and masks for this split\n",
    "    input_images_dir = os.path.join(base_input_image_dir, split_name, 'images')\n",
    "    input_masks_dir = os.path.join(base_input_mask_dir, split_name, 'masks')\n",
    "\n",
    "    # Construct the single output directory for ALL patches of this split\n",
    "    output_split_dir = os.path.join(base_output_patch_dir, split_name)\n",
    "\n",
    "    # Check if input directories exist\n",
    "    if not os.path.isdir(input_images_dir):\n",
    "        print(f\"Skipping split '{split_name}': Image input directory not found at {input_images_dir}\", file=sys.stderr)\n",
    "        return\n",
    "    if not os.path.isdir(input_masks_dir):\n",
    "        print(f\"Skipping split '{split_name}': Mask input directory not found at {input_masks_dir}\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # Create the single output directory for this split's patches if it doesn't exist\n",
    "    os.makedirs(output_split_dir, exist_ok=True)\n",
    "\n",
    "    # List all files in the input image directory\n",
    "    # Filter for .png files (case-insensitive)\n",
    "    image_files = [f for f in os.listdir(input_images_dir) if os.path.isfile(os.path.join(input_images_dir, f)) and f.lower().endswith('.png')]\n",
    "    print(f\"Found {len(image_files)} image files in {input_images_dir}\")\n",
    "\n",
    "    total_patches_saved = 0\n",
    "    processed_files_count = 0\n",
    "    failed_files_count = 0\n",
    "\n",
    "    # Iterate through each image file\n",
    "    for image_filename in image_files:\n",
    "        # Get the base filename without extension\n",
    "        base_name = os.path.splitext(image_filename)[0]\n",
    "\n",
    "        # Construct the full paths for the image and corresponding mask\n",
    "        input_image_path = os.path.join(input_images_dir, image_filename)\n",
    "        input_mask_path = os.path.join(input_masks_dir, f\"{base_name}.npy\") # Assuming mask has same base name but .npy\n",
    "\n",
    "        # Check if the corresponding mask file exists\n",
    "        if not os.path.exists(input_mask_path):\n",
    "            print(f\"Skipping image {image_filename}: Corresponding mask not found at {input_mask_path}\", file=sys.stderr)\n",
    "            failed_files_count += 1\n",
    "            continue # Skip to the next image\n",
    "\n",
    "        # Call the patch splitting function for this image/mask pair\n",
    "        # Pass the single output directory for the split and the image base name\n",
    "        num_patches = split_and_save_patches(\n",
    "            input_image_path,\n",
    "            input_mask_path,\n",
    "            output_split_dir, # Pass the single output directory\n",
    "            base_name,        # Pass the image base name\n",
    "            patch_size,\n",
    "            step\n",
    "        )\n",
    "\n",
    "        if num_patches >= 0: # Success or 0 patches generated\n",
    "            total_patches_saved += num_patches\n",
    "            processed_files_count += 1\n",
    "        else: # Error occurred\n",
    "            failed_files_count += 1\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Finished processing split: {split_name}\")\n",
    "    print(f\"Total image/mask pairs processed: {processed_files_count}\")\n",
    "    print(f\"Total image/mask pairs failed: {failed_files_count}\")\n",
    "    print(f\"Total patches saved across all processed pairs: {total_patches_saved}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- Main Execution Block (suitable for a notebook cell) ---\n",
    "\n",
    "# Define the base paths for input images, input masks, and output patches\n",
    "# Adjust these paths based on your actual data structure\n",
    "base_input_image_dir = \"./data/DSB2018/visual\" # Assuming images are in ./data/DSB2018/visual/[split]/...\n",
    "base_input_mask_dir = \"./data/DSB2018/visual\"  # Assuming masks are in ./data/DSB2018/visual/[split]/...\n",
    "base_output_patch_dir = \"./data/DSB2018/data256/hovernet\" # Where the new split folders containing ALL patches will be created\n",
    "\n",
    "# Define the splits to process\n",
    "splits_to_process = ['train', 'test', 'val'] # Process all desired splits\n",
    "\n",
    "# Define patch size and step\n",
    "patch_size = 256\n",
    "step = 256 # Use step < patch_size for overlapping patches\n",
    "\n",
    "# Process each specified split\n",
    "for split in splits_to_process:\n",
    "    process_split_for_patching(\n",
    "        split,\n",
    "        base_input_image_dir,\n",
    "        base_input_mask_dir,\n",
    "        base_output_patch_dir,\n",
    "        patch_size,\n",
    "        step\n",
    "    )\n",
    "\n",
    "print(\"\\nPatch splitting process complete for all specified splits.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generating the training dataset from above .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 602/602 [00:09<00:00, 64.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 100%|██████████| 89/89 [00:01<00:00, 60.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split: val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing val: 100%|██████████| 109/109 [00:01<00:00, 65.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def process_single_npy(npy_filepath, output_img_dir, output_mask_dir, output_inst_dir):\n",
    "    \"\"\"\n",
    "    Convert a single .npy file (image + mask/instance) to image and mask PNGs,\n",
    "    and save the instance data as .npy.\n",
    "\n",
    "    Args:\n",
    "        npy_filepath (str): Full path to the input .npy file.\n",
    "        output_img_dir (str): Directory to save the image PNG.\n",
    "        output_mask_dir (str): Directory to save the mask PNG.\n",
    "        output_inst_dir (str): Directory to save the instance .npy file.\n",
    "                               This should already include the split subdirectory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the .npy file\n",
    "        data = np.load(npy_filepath)\n",
    "\n",
    "        # Ensure data has expected dimensions (height, width, channels)\n",
    "        if data.ndim != 3 or data.shape[-1] < 4:\n",
    "             print(f\"Warning: Skipping file {npy_filepath} - expected 3 dimensions with at least 4 channels, but got {data.shape}\")\n",
    "             return\n",
    "\n",
    "        # Separate image data (first 3 channels)\n",
    "        image_data = data[..., :3]\n",
    "        # Assuming image data is in 0-255 range or can be cast to uint8 directly\n",
    "        image_data = image_data.astype(np.uint8)\n",
    "\n",
    "        # Separate mask/instance data (4th channel)\n",
    "        instance_data = data[..., 3] # Keep original instance IDs\n",
    "\n",
    "        # Create binary mask (foreground > 0)\n",
    "        mask_data = instance_data.copy() # Use the copied instance data\n",
    "        mask_data[mask_data > 0] = 1\n",
    "        mask_data = mask_data.astype(np.uint8) # Mask should be 0 or 1\n",
    "\n",
    "         # Handle potential grayscale masks if data[..., 3] was not 2D but 3D with channel 1\n",
    "        if mask_data.ndim == 3 and mask_data.shape[-1] == 1:\n",
    "             mask_data = np.squeeze(mask_data, axis=-1) # Remove single channel dimension\n",
    "\n",
    "\n",
    "        # Convert image and binary mask arrays to PIL Images\n",
    "        image = Image.fromarray(image_data)\n",
    "        mask = Image.fromarray(mask_data)\n",
    "\n",
    "        # Generate output filenames\n",
    "        # Use os.path.basename to get just the filename from the full path\n",
    "        npy_filename = os.path.basename(npy_filepath)\n",
    "        base_name = os.path.splitext(npy_filename)[0] # Get filename without extension\n",
    "\n",
    "        image_name = f\"{base_name}.png\"\n",
    "        mask_name_png = f\"{base_name}.png\" # Mask will also be a PNG\n",
    "        instance_name_npy = f\"{base_name}.npy\" # Instance data stays NPY\n",
    "\n",
    "        output_img_path = os.path.join(output_img_dir, image_name)\n",
    "        output_mask_path_png = os.path.join(output_mask_dir, mask_name_png)\n",
    "        output_instance_path_npy = os.path.join(output_inst_dir, instance_name_npy)\n",
    "\n",
    "        # Save the image and mask\n",
    "        image.save(output_img_path)\n",
    "        mask.save(output_mask_path_png)\n",
    "\n",
    "        # Save the original instance data as .npy\n",
    "        np.save(output_instance_path_npy, instance_data)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {npy_filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {npy_filepath}: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    splits = ['train', 'test', 'val']\n",
    "\n",
    "    # Define base paths *without* the split name\n",
    "    source_base_path = \"./data/DSB2018/data256/hovernet\"\n",
    "    out_img_base_dir = \"./data/DSB2018/data256/mmseg/images\"\n",
    "    out_mask_base_dir = \"./data/DSB2018/data256/mmseg/masks\"\n",
    "    out_inst_base_dir = \"./data/DSB2018/data256/mmseg/insts\"\n",
    "\n",
    "    # Loop through each split\n",
    "    for split in splits:\n",
    "        # Construct the full source path for the current split\n",
    "        source_split_path = os.path.join(source_base_path, split)\n",
    "\n",
    "        # Construct the full output directory paths for the current split\n",
    "        output_img_split_dir = os.path.join(out_img_base_dir, split)\n",
    "        output_mask_split_dir = os.path.join(out_mask_base_dir, split)\n",
    "        output_inst_split_dir = os.path.join(out_inst_base_dir, split)\n",
    "\n",
    "        # Create the output directories for this split if they don't exist\n",
    "        os.makedirs(output_img_split_dir, exist_ok=True)\n",
    "        os.makedirs(output_mask_split_dir, exist_ok=True)\n",
    "        os.makedirs(output_inst_split_dir, exist_ok=True)\n",
    "\n",
    "        # Check if the source split folder exists\n",
    "        if not os.path.exists(source_split_path):\n",
    "            print(f\"Warning: Source directory for split '{split}' not found: {source_split_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing split: {split}\")\n",
    "\n",
    "        # List files in the current split directory\n",
    "        try:\n",
    "            split_file_list = os.listdir(source_split_path)\n",
    "        except Exception as e:\n",
    "             print(f\"Error listing files in {source_split_path}: {e}. Skipping split.\")\n",
    "             continue\n",
    "\n",
    "        # Filter for .npy files to avoid processing directories or other files\n",
    "        npy_files_in_split = [f for f in split_file_list if f.endswith('.npy')]\n",
    "\n",
    "        if not npy_files_in_split:\n",
    "             print(f\"No .npy files found in {source_split_path}. Skipping split.\")\n",
    "             continue\n",
    "\n",
    "\n",
    "        # Process each .npy file in the current split with a progress bar\n",
    "        for filename in tqdm(npy_files_in_split, desc=f\"Processing {split}\"):\n",
    "            full_npy_path = os.path.join(source_split_path, filename)\n",
    "\n",
    "            # Call the processing function with full input path and split-specific output directories\n",
    "            process_single_npy(full_npy_path, output_img_split_dir, output_mask_split_dir, output_inst_split_dir)\n",
    "\n",
    "    print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generating the file list with .txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating file list for split: train\n",
      "File list saved successfully to ./data/DSB2018/data256/mmseg/train.txt\n",
      "Generating file list for split: test\n",
      "File list saved successfully to ./data/DSB2018/data256/mmseg/test.txt\n",
      "Generating file list for split: val\n",
      "File list saved successfully to ./data/DSB2018/data256/mmseg/val.txt\n",
      "All file lists generated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def generate_file_list(directory, output_txt):\n",
    "    \"\"\"\n",
    "    Generate a text file containing the file names (without extensions)\n",
    "    of all files in a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing the files.\n",
    "        output_txt (str): Path to the output text file.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists before writing the file\n",
    "    output_dir = os.path.dirname(output_txt)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Check if the source directory exists\n",
    "        if not os.path.exists(directory):\n",
    "            print(f\"Warning: Source directory not found: {directory}. Skipping.\")\n",
    "            return\n",
    "\n",
    "        # List all entries in the directory\n",
    "        entries = os.listdir(directory)\n",
    "\n",
    "        # Filter out directories and get only files\n",
    "        files = [entry for entry in entries if os.path.isfile(os.path.join(directory, entry))]\n",
    "\n",
    "        # Extract file names without extensions\n",
    "        file_names = [os.path.splitext(file)[0] for file in files]\n",
    "\n",
    "        # Write file names to the output text file\n",
    "        with open(output_txt, 'w') as f:\n",
    "            for name in file_names:\n",
    "                f.write(name + '\\n')\n",
    "\n",
    "        print(f\"File list saved successfully to {output_txt}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {directory}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the splits\n",
    "    splits = ['train', 'test', 'val']\n",
    "\n",
    "    # Define the base directory where the image folders for splits are located\n",
    "    base_image_directory = \"./data/DSB2018/data256/mmseg/images\"\n",
    "\n",
    "    # Define the base directory where the output text files should be saved\n",
    "    base_output_directory = \"./data/DSB2018/data256/mmseg\"\n",
    "\n",
    "    # Loop through each split and generate the corresponding text file\n",
    "    for split in splits:\n",
    "        # Construct the full path to the image directory for the current split\n",
    "        image_directory_split = os.path.join(base_image_directory, split)\n",
    "\n",
    "        # Construct the full path for the output text file for the current split\n",
    "        output_file_split = os.path.join(base_output_directory, f\"{split}.txt\")\n",
    "\n",
    "        print(f\"Generating file list for split: {split}\")\n",
    "\n",
    "        # Call the function to generate the file list for the current split\n",
    "        generate_file_list(image_directory_split, output_file_split)\n",
    "\n",
    "    print(\"All file lists generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Generating four-color encoding .png and adjacency .yaml files from Inst file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "def compute_adjacency_map(instance_mask):\n",
    "    \"\"\"\n",
    "    计算细胞核实例的邻接关系图。\n",
    "    \n",
    "    Args:\n",
    "        instance_mask (np.Tensor): 细胞核实例编码图，形状为 (H, W)。\n",
    "    \n",
    "    Returns:\n",
    "        adjacency_map (dict): 邻接关系图，键是实例ID，值是相邻实例的ID列表。\n",
    "    \"\"\"\n",
    "    instance_ids = np.unique(instance_mask)\n",
    "    adjacency_map = {int(i): set() for i in instance_ids if i != 0}\n",
    "\n",
    "    # 定义邻接核 (8邻域)\n",
    "    kernel = np.ones((3, 3), dtype=np.int32)\n",
    "    \n",
    "    for instance_id in adjacency_map.keys():\n",
    "        # 创建当前实例的二值掩码\n",
    "        binary_mask = (instance_mask == instance_id).astype(np.int32)\n",
    "        \n",
    "        # 使用卷积判断边界是否接触其他实例\n",
    "        boundary = convolve(binary_mask, kernel, mode='constant', cval=0)\n",
    "        neighbors = np.unique(instance_mask * (boundary > 0))\n",
    "        \n",
    "        # 记录相邻的实例ID，排除自己和背景\n",
    "        adjacency_map[instance_id].update(\n",
    "            int(neighbor_id) for neighbor_id in neighbors if neighbor_id != instance_id and neighbor_id != 0\n",
    "        )\n",
    "\n",
    "    return adjacency_map\n",
    "\n",
    "def save_adjacency_map_to_yaml(adjacency_map, file_path):\n",
    "    \"\"\"\n",
    "    将邻接关系字典保存为 YAML 文件。\n",
    "    \n",
    "    Args:\n",
    "        adjacency_map (dict): 邻接关系字典。\n",
    "        file_path (str): 输出的 YAML 文件路径。\n",
    "    \"\"\"\n",
    "    # 转换 set 为 list，确保 YAML 可序列化\n",
    "    adjacency_map_serializable = {int(key): list(value) for key, value in adjacency_map.items()}\n",
    "    \n",
    "    # 保存为 YAML 文件\n",
    "    with open(file_path, 'w') as f:\n",
    "        yaml.dump(adjacency_map_serializable, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "\n",
    "\n",
    "stage = \"test\"\n",
    "inst_path = \"./data/DSB2018/mmseg/inst\"\n",
    "save_path = \"./data/DSB2018/mmseg/adjacency\"\n",
    "\n",
    "\n",
    "for f in tqdm(os.listdir(f\"{inst_path}/{stage}\")):\n",
    "    if f.endswith(\".npy\"):\n",
    "        f_name = f.split(\".\")[0]\n",
    "        mask = np.load(f\"{inst_path}/{stage}/{f}\")\n",
    "        adjacency_map = compute_adjacency_map(mask)\n",
    "        # 保存为 YAML 文件\n",
    "        output_file = f\"{save_path}/{stage}/{f_name}.yaml\"\n",
    "        save_adjacency_map_to_yaml(adjacency_map, output_file)\n",
    "\n",
    "    # print(f\"邻接关系字典已保存到 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
